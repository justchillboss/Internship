{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71dbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ddcdb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e005967",
   "metadata": {},
   "source": [
    "## 1. Scrape the details of most viewed videos on YouTube from Wikipedia.   Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "### A) Rank B) Name C) Artist D) Upload date E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749a3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "driver = webdriver.Chrome(\"F:\\Program Files (x86\\chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181b7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "147af8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "UploadDate = []\n",
    "Views = []\n",
    "test = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text.split(\"\\\"\")[1])\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"_\")\n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[3]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"_\")\n",
    "\n",
    "    \n",
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,' //table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        UploadDate.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    UploadDate.append('-')\n",
    "    \n",
    "\n",
    "# Scraping Views of videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text+\"M\")\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"_\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef05e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = pd.DataFrame({\"Rank\":Rank,\n",
    "                         \"Name of Video\":Name,\n",
    "                         \"Artist\":Artist,\n",
    "                         \"Upload Date\":UploadDate,\n",
    "                         \"Views on Video\":Views})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "065ead7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name of Video</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views on Video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.73M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.14M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.69M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.15M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.97M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.86M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.26M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.14M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.89M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.87M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.77M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.32M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.87M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.86M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.78M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.77M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.65M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.61M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.58M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.56M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.50M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.44M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.42M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.42M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.42M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.40M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.38M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.37M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.37M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                              Name of Video  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                                  Bath Song   \n",
       "4    5.                               Shape of You   \n",
       "5    6.                              See You Again   \n",
       "6    7.                Phonics Song with Two Words   \n",
       "7    8.                          Wheels on the Bus   \n",
       "8    9.                                Uptown Funk   \n",
       "9   10.  Learning Colors – Colorful Eggs on a Farm   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.   Masha and the Bear – Recipe for Disaster   \n",
       "12  13.                             Dame Tu Cosita   \n",
       "13  14.                                     Axel F   \n",
       "14  15.                                      Sugar   \n",
       "15  16.                                       Roar   \n",
       "16  17.                             Counting Stars   \n",
       "17  18.                                      Sorry   \n",
       "18  19.                        Baa Baa Black Sheep   \n",
       "19  20.                          Thinking Out Loud   \n",
       "20  21.           Waka Waka (This Time for Africa)   \n",
       "21  22.                                 Dark Horse   \n",
       "22  23.                                      Faded   \n",
       "23  24.                                    Perfect   \n",
       "24  25.                             Lakdi Ki Kathi   \n",
       "25  26.                                 Let Her Go   \n",
       "26  27.                             Girls Like You   \n",
       "27  28.          Humpty the train on a fruits ride   \n",
       "28  29.                                    Lean On   \n",
       "29  30.                                   Bailando   \n",
       "\n",
       "                                           Artist        Upload Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "8                                     Mark Ronson  November 19, 2014   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                     Crazy Frog      June 16, 2009   \n",
       "14                                       Maroon 5   January 14, 2015   \n",
       "15                                     Katy Perry  September 5, 2013   \n",
       "16                                    OneRepublic       May 31, 2013   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "19                                     Ed Sheeran    October 7, 2014   \n",
       "20                                        Shakira       June 4, 2010   \n",
       "21                                     Katy Perry  February 20, 2014   \n",
       "22                                    Alan Walker   December 3, 2015   \n",
       "23                                     Ed Sheeran   November 9, 2017   \n",
       "24                                   Jingle Toons      June 14, 2018   \n",
       "25                                      Passenger      July 25, 2012   \n",
       "26                                       Maroon 5       May 31, 2018   \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "28                                    Major Lazer     March 22, 2015   \n",
       "29                               Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "   Views on Video  \n",
       "0          12.73M  \n",
       "1           8.14M  \n",
       "2           6.69M  \n",
       "3           6.15M  \n",
       "4           5.97M  \n",
       "5           5.86M  \n",
       "6           5.26M  \n",
       "7           5.14M  \n",
       "8           4.89M  \n",
       "9           4.87M  \n",
       "10          4.77M  \n",
       "11          4.55M  \n",
       "12          4.32M  \n",
       "13          3.87M  \n",
       "14          3.86M  \n",
       "15          3.78M  \n",
       "16          3.77M  \n",
       "17          3.65M  \n",
       "18          3.61M  \n",
       "19          3.58M  \n",
       "20          3.56M  \n",
       "21          3.50M  \n",
       "22          3.44M  \n",
       "23          3.42M  \n",
       "24          3.42M  \n",
       "25          3.42M  \n",
       "26          3.40M  \n",
       "27          3.38M  \n",
       "28          3.37M  \n",
       "29          3.37M  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2989a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572dcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa4f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e5ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f42a5951",
   "metadata": {},
   "source": [
    "## 2. Scrape the details teamIndia’sinternationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020f83f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Getting the webpage of mentioned url \n",
    "url=('https://www.bcci.tv/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5c2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clickin on International tab\n",
    "International = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a') # click button\n",
    "International.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8ca95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List\n",
    "Name=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "#Scrapping Name\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]'):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "    \n",
    "#Scrapping Series\n",
    "\n",
    "try:    \n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]'):\n",
    "        Series.append(i.text[10:27])\n",
    "except NoSuchElementException:\n",
    "    Series.append('-')\n",
    "#scrapping Place\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]'):\n",
    "        Place.append(i.text.split(\"-\")[1].strip())\n",
    "except NoSuchElementException:\n",
    "    Place.append('-')\n",
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('-')\n",
    "#Scrapping Time\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]'):\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Time.append('-')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8289ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = pd.DataFrame({\"Title\":Name,\n",
    "                     \"Series Name\": Series,\n",
    "                     \"Place\": Place,\n",
    "                     \"Date\":Date,\n",
    "                     \"Time\":Time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "812c4656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP FINAL 2023</td>\n",
       "      <td>TEST CHAMPIONSHIP</td>\n",
       "      <td>Kennington Oval, London</td>\n",
       "      <td>7 JUN 2023</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Title        Series Name  \\\n",
       "0  ICC WORLD TEST CHAMPIONSHIP FINAL 2023  TEST CHAMPIONSHIP   \n",
       "\n",
       "                     Place        Date         Time  \n",
       "0  Kennington Oval, London  7 JUN 2023  3:30 PM IST  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e2f15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8b274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d1f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3597b272",
   "metadata": {},
   "source": [
    "## 3. Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1792269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.statisticstimes.com')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdf42b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div[1]/div/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5efaa03a",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Clicking on Economy button\n",
    "driver.find_element(By.XPATH,\"//div[@class='navbar']/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02dadc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on India\n",
    "driver.find_element(By.XPATH,\"//div[@class='dropdown-content']/a[3]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef5dfab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48c919c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDPbillion = []\n",
    "# Scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "# Scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "# Scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "# Scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "# Scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDPbillion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDPbillion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b05ab020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP2</th>\n",
       "      <th>SHARE</th>\n",
       "      <th>GDPbillion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                      STATE      GSDP2   SHARE GDPbillion\n",
       "0     1                Maharashtra  2,632,792  13.94%    399.921\n",
       "1     2                 Tamil Nadu  1,630,208   8.63%    247.629\n",
       "2     3              Uttar Pradesh  1,584,764   8.39%    240.726\n",
       "3     4                    Gujarat  1,502,899   7.96%    228.290\n",
       "4     5                  Karnataka  1,493,127   7.91%    226.806\n",
       "..  ...                        ...        ...     ...        ...\n",
       "61   29                     Sikkim     25,141   0.15%     17,060\n",
       "62   30                   Nagaland     24,534   0.15%          -\n",
       "63   31          Arunachal Pradesh     22,488   0.13%          -\n",
       "64   32                    Mizoram     20,947   0.13%     17,797\n",
       "65   33  Andaman & Nicobar Islands          -       -          -\n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDIA=pd.DataFrame()\n",
    "INDIA['RANK']=Rank\n",
    "INDIA['STATE']=State\n",
    "INDIA['GSDP2']=GSDP2\n",
    "INDIA['SHARE']=Share\n",
    "INDIA['GDPbillion']=GDPbillion\n",
    "INDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6228ccc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b76296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2addc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e0baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "940d0373",
   "metadata": {},
   "source": [
    "## 4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87d776ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url=('https://github.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "40bbbff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on explore\n",
    "\n",
    "explore = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "try:\n",
    "    explore.click()\n",
    "    trending = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "    trending.click()\n",
    "    time.sleep(5)\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "688754f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list:\n",
    "URLs = []\n",
    "\n",
    "\n",
    "#Fetching urls for each repository\n",
    "repository = driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in repository:\n",
    "    URLs.append(i.get_attribute(\"href\"))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e38b5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []\n",
    "\n",
    "# Scraping data from all repository page\n",
    "for i in URLs:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    # Repository Titles\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH,'//strong[@class=\"mr-2 flex-self-stretch\"]')\n",
    "        repository_title.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "    \n",
    "    # Description\n",
    "    \n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH,'//p[@class=\"f4 my-3\"]')\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "    \n",
    "    # Contributor\n",
    "    \n",
    "    try:\n",
    "        contributor = driver.find_element(By.XPATH,'//div[@class=\"mt-3\"]')\n",
    "        Contributors.append(contributor.text.split(\"+\")[-1].strip())\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "        \n",
    "   # Languages \n",
    "    lang=[]\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]'):\n",
    "            lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab155179",
   "metadata": {},
   "outputs": [],
   "source": [
    "github = pd.DataFrame({\"Repository Title\":repository_title,\n",
    "                      \"Description\": Description,\n",
    "                      \"Contributors\": Contributors,\n",
    "                      \"Languages Used\":Language})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c637078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors</th>\n",
       "      <th>Languages Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4free</td>\n",
       "      <td>decentralising the Ai Industry, just some lang...</td>\n",
       "      <td>26 contributors</td>\n",
       "      <td>[Python, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AudioGPT</td>\n",
       "      <td>AudioGPT: Understanding and Generating Speech,...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Track-Anything</td>\n",
       "      <td>Track-Anything is a flexible and interactive t...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tabby</td>\n",
       "      <td>A terminal for a more modern age</td>\n",
       "      <td>174 releases</td>\n",
       "      <td>[TypeScript, Pug, SCSS, JavaScript, C++, Batch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chart-gpt</td>\n",
       "      <td>AI tool to build charts based on text input</td>\n",
       "      <td>4 contributors</td>\n",
       "      <td>[TypeScript, CSS, JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>swift-foundation</td>\n",
       "      <td>The Foundation project</td>\n",
       "      <td>2 contributors</td>\n",
       "      <td>[Swift, C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>databerry</td>\n",
       "      <td>The no-code platform for connecting custom dat...</td>\n",
       "      <td>-</td>\n",
       "      <td>[TypeScript, JavaScript, CSS, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IF</td>\n",
       "      <td>-</td>\n",
       "      <td>1 release</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Segment-Everything-Everywhere-All-At-Once</td>\n",
       "      <td>Official implementation of the paper \"Segment ...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Cuda, C++, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WizardLM</td>\n",
       "      <td>WizardLM: Empowering Large Pre-Trained Languag...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QQFlacMusicDownloader</td>\n",
       "      <td>[秋城落叶] QQ 音乐源无损歌曲下载</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Vue, JavaScript, TypeScript, Java, CS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>awesome</td>\n",
       "      <td>😎 Awesome lists about all kinds of interesting...</td>\n",
       "      <td>545 contributors</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ai-collection</td>\n",
       "      <td>The Generative AI Landscape - A Collection of ...</td>\n",
       "      <td>31 contributors</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PentestGPT</td>\n",
       "      <td>A GPT-empowered penetration testing tool</td>\n",
       "      <td>3 releases</td>\n",
       "      <td>[Python, HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hyperswitch</td>\n",
       "      <td>An Open Source Financial Switch to make Paymen...</td>\n",
       "      <td>10 releases</td>\n",
       "      <td>[Rust, Nix, JavaScript, Shell, Dockerfile, Mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dndserver</td>\n",
       "      <td>Dark and Darker private server implementation ...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NeMo-Guardrails</td>\n",
       "      <td>NeMo Guardrails is an open-source toolkit for ...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>loopgpt</td>\n",
       "      <td>Modular Auto-GPT Framework</td>\n",
       "      <td>1 release</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>skyagi</td>\n",
       "      <td>SkyAGI: Emerging human-behavior simulation cap...</td>\n",
       "      <td>19 releases</td>\n",
       "      <td>[Python, Shell, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Auto-GPT-MetaTrader-Plugin</td>\n",
       "      <td>The AutoGPT MetaTrader Plugin is a software to...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Batchfile, Shell, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LLaMA-Adapter</td>\n",
       "      <td>Fine-tuning LLaMA to follow Instructions withi...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Motrix</td>\n",
       "      <td>A full-featured download manager.</td>\n",
       "      <td>17 releases</td>\n",
       "      <td>[JavaScript, Vue, SCSS, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>trader</td>\n",
       "      <td>交易模块</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WebGPT</td>\n",
       "      <td>Run GPT model on the browser with WebGPU. An i...</td>\n",
       "      <td>-</td>\n",
       "      <td>[JavaScript, HTML, Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>angular</td>\n",
       "      <td>The modern web developer’s platform</td>\n",
       "      <td>267 releases</td>\n",
       "      <td>[TypeScript, JavaScript, Starlark, HTML, CSS, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Repository Title  \\\n",
       "0                                    gpt4free   \n",
       "1                                    AudioGPT   \n",
       "2                              Track-Anything   \n",
       "3                                       tabby   \n",
       "4                                   chart-gpt   \n",
       "5                            swift-foundation   \n",
       "6                                   databerry   \n",
       "7                                          IF   \n",
       "8   Segment-Everything-Everywhere-All-At-Once   \n",
       "9                                    WizardLM   \n",
       "10                      QQFlacMusicDownloader   \n",
       "11                                    awesome   \n",
       "12                              ai-collection   \n",
       "13                                 PentestGPT   \n",
       "14                                hyperswitch   \n",
       "15                                  dndserver   \n",
       "16                            NeMo-Guardrails   \n",
       "17                                    loopgpt   \n",
       "18                                     skyagi   \n",
       "19                 Auto-GPT-MetaTrader-Plugin   \n",
       "20                              LLaMA-Adapter   \n",
       "21                                     Motrix   \n",
       "22                                     trader   \n",
       "23                                     WebGPT   \n",
       "24                                    angular   \n",
       "\n",
       "                                          Description      Contributors  \\\n",
       "0   decentralising the Ai Industry, just some lang...   26 contributors   \n",
       "1   AudioGPT: Understanding and Generating Speech,...                 -   \n",
       "2   Track-Anything is a flexible and interactive t...                 -   \n",
       "3                    A terminal for a more modern age      174 releases   \n",
       "4         AI tool to build charts based on text input    4 contributors   \n",
       "5                              The Foundation project    2 contributors   \n",
       "6   The no-code platform for connecting custom dat...                 -   \n",
       "7                                                   -         1 release   \n",
       "8   Official implementation of the paper \"Segment ...                 -   \n",
       "9   WizardLM: Empowering Large Pre-Trained Languag...                 -   \n",
       "10                                [秋城落叶] QQ 音乐源无损歌曲下载                 -   \n",
       "11  😎 Awesome lists about all kinds of interesting...  545 contributors   \n",
       "12  The Generative AI Landscape - A Collection of ...   31 contributors   \n",
       "13           A GPT-empowered penetration testing tool        3 releases   \n",
       "14  An Open Source Financial Switch to make Paymen...       10 releases   \n",
       "15  Dark and Darker private server implementation ...                 -   \n",
       "16  NeMo Guardrails is an open-source toolkit for ...                 -   \n",
       "17                         Modular Auto-GPT Framework         1 release   \n",
       "18  SkyAGI: Emerging human-behavior simulation cap...       19 releases   \n",
       "19  The AutoGPT MetaTrader Plugin is a software to...                 -   \n",
       "20  Fine-tuning LLaMA to follow Instructions withi...                 -   \n",
       "21                  A full-featured download manager.       17 releases   \n",
       "22                                               交易模块                 -   \n",
       "23  Run GPT model on the browser with WebGPU. An i...                 -   \n",
       "24                The modern web developer’s platform      267 releases   \n",
       "\n",
       "                                       Languages Used  \n",
       "0                                     [Python, Other]  \n",
       "1                                     [Python, Shell]  \n",
       "2                                      [Python, HTML]  \n",
       "3   [TypeScript, Pug, SCSS, JavaScript, C++, Batch...  \n",
       "4                       [TypeScript, CSS, JavaScript]  \n",
       "5                                          [Swift, C]  \n",
       "6                [TypeScript, JavaScript, CSS, Other]  \n",
       "7                                            [Python]  \n",
       "8                          [Python, Cuda, C++, Shell]  \n",
       "9                                            [Python]  \n",
       "10  [Python, Vue, JavaScript, TypeScript, Java, CS...  \n",
       "11                                                 []  \n",
       "12                                                 []  \n",
       "13                                     [Python, HTML]  \n",
       "14  [Rust, Nix, JavaScript, Shell, Dockerfile, Mak...  \n",
       "15                                    [Python, Other]  \n",
       "16                                     [Python, HTML]  \n",
       "17                                           [Python]  \n",
       "18                          [Python, Shell, Makefile]  \n",
       "19               [Python, Batchfile, Shell, Makefile]  \n",
       "20                                    [Python, Shell]  \n",
       "21                     [JavaScript, Vue, SCSS, Other]  \n",
       "22                                           [Python]  \n",
       "23                         [JavaScript, HTML, Python]  \n",
       "24  [TypeScript, JavaScript, Starlark, HTML, CSS, ...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01402c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d586ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88350f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a80a57f7",
   "metadata": {},
   "source": [
    "## 5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6fe9564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "# Getting the webpage of mentioned url \n",
    "driver.get('https://www.billboard.com/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "07143559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on charts\n",
    "charts=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8bd939f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_chart = driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f06952fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "Song_Name = []\n",
    "Artist_Name = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ce901fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping name\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]'):\n",
    "    Song_Name.append(i.text)\n",
    "len(Song_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6238a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrappin Artist name 1 st one\n",
    "Artist_Name.append(driver.find_element(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\").text)\n",
    "#Remainig Artist Name\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "Artist_Name.extend([i.text for i in artistTag])\n",
    "#Scapping Rank\n",
    "rank=[]\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "rank.extend([i.text for i in rankTag[:3]])\n",
    "#Remaining RAnk\n",
    "Rank=[]\n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "Rank.extend([i.text for i in RankTag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d0fc886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7ab3b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing as per requirement\n",
    "lastweekpos=Rank[0::3]\n",
    "lastweekpos.insert(0,rank[0])\n",
    "peakPos=Rank[1::3]\n",
    "peakPos.insert(0,rank[1])\n",
    "weeksonBoard=Rank[2::3]\n",
    "weeksonBoard.insert(0,rank[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "adc18cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongName</th>\n",
       "      <th>ArtistName</th>\n",
       "      <th>Last Week</th>\n",
       "      <th>PeekPosition</th>\n",
       "      <th>Weeks On board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kill Bill\\nSZA\\n4\\n1\\n19</td>\n",
       "      <td>SZA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Last Night\\nMorgan Wallen\\n1\\n1\\n12</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flowers\\nMiley Cyrus\\n3\\n1\\n14</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Princess Diana\\nIce Spice &amp; Nicki Minaj\\n-\\n4\\n1</td>\n",
       "      <td>Ice Spice &amp; Nicki Minaj</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ella Baila Sola\\nEslabon Armado X Peso Pluma\\n...</td>\n",
       "      <td>Eslabon Armado X Peso Pluma</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Memory Lane\\nOld Dominion\\n96\\n96\\n3</td>\n",
       "      <td>Old Dominion</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Love Again\\nThe Kid LAROI\\n88\\n40\\n12</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>'98 Braves\\nMorgan Wallen\\n100\\n27\\n7</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Di Que Si\\nGrupo Marca Registrada X Grupo Fron...</td>\n",
       "      <td>Grupo Marca Registrada X Grupo Frontera</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>It Matters To Her\\nScotty McCreery\\n-\\n100\\n1</td>\n",
       "      <td>Scotty McCreery</td>\n",
       "      <td>93</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             SongName  \\\n",
       "0                            Kill Bill\\nSZA\\n4\\n1\\n19   \n",
       "1                 Last Night\\nMorgan Wallen\\n1\\n1\\n12   \n",
       "2                      Flowers\\nMiley Cyrus\\n3\\n1\\n14   \n",
       "3    Princess Diana\\nIce Spice & Nicki Minaj\\n-\\n4\\n1   \n",
       "4   Ella Baila Sola\\nEslabon Armado X Peso Pluma\\n...   \n",
       "..                                                ...   \n",
       "95               Memory Lane\\nOld Dominion\\n96\\n96\\n3   \n",
       "96              Love Again\\nThe Kid LAROI\\n88\\n40\\n12   \n",
       "97              '98 Braves\\nMorgan Wallen\\n100\\n27\\n7   \n",
       "98  Di Que Si\\nGrupo Marca Registrada X Grupo Fron...   \n",
       "99      It Matters To Her\\nScotty McCreery\\n-\\n100\\n1   \n",
       "\n",
       "                                 ArtistName Last Week PeekPosition  \\\n",
       "0                                       SZA         4            1   \n",
       "1                             Morgan Wallen         1            1   \n",
       "2                               Miley Cyrus         3            1   \n",
       "3                   Ice Spice & Nicki Minaj         -            4   \n",
       "4               Eslabon Armado X Peso Pluma        10            5   \n",
       "..                                      ...       ...          ...   \n",
       "95                             Old Dominion        98           50   \n",
       "96                            The Kid LAROI                          \n",
       "97                            Morgan Wallen        71           71   \n",
       "98  Grupo Marca Registrada X Grupo Frontera                          \n",
       "99                          Scotty McCreery        93           30   \n",
       "\n",
       "   Weeks On board  \n",
       "0              19  \n",
       "1              12  \n",
       "2              14  \n",
       "3               1  \n",
       "4               5  \n",
       "..            ...  \n",
       "95             17  \n",
       "96                 \n",
       "97              2  \n",
       "98                 \n",
       "99              7  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df=pd.DataFrame()\n",
    "df['SongName']=Song_Name[0:100]\n",
    "df['ArtistName']=Artist_Name\n",
    "df['Last Week']=lastweekpos[0:100]\n",
    "df[\"PeekPosition\"]=peakPos[0:100]\n",
    "df['Weeks On board']=weeksonBoard[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b894dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efebfd39",
   "metadata": {},
   "source": [
    "## 6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fb7b7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# get webpage\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0dc2fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Bookname = []\n",
    "Authorname = []\n",
    "Volumessold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ec074bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr/td[2]\"):\n",
    "    Bookname.append(i.text)\n",
    "    \n",
    "#Scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Authorname.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Authorname.append('-')\n",
    "time.sleep(1)\n",
    "\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[4]\"):\n",
    "    Volumessold.append(i.text)\n",
    "    \n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "108300cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe for scraped data\n",
    "Novels=pd.DataFrame({})\n",
    "Novels['Book Name'] = Bookname\n",
    "Novels['Author'] = Authorname\n",
    "Novels['Volume sold'] = Volumessold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "80c11ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd179136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7369bbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97cc07b9",
   "metadata": {},
   "source": [
    "## 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7fd83d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "# get webpage\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "866d15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n",
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4dc7b9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,154,451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,236,296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,023,495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>301,152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>260,123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>206,931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>42,974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>256,627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,154,451  \n",
       "1    51 min     8.7  1,236,296  \n",
       "2    44 min     8.1  1,023,495  \n",
       "3    60 min     7.5    301,152  \n",
       "4    43 min     7.6    260,123  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     51,431  \n",
       "96   50 min     7.8     63,466  \n",
       "97   42 min     8.1    206,931  \n",
       "98   45 min       7     42,974  \n",
       "99  572 min     8.6    256,627  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for scraped data\n",
    "TVseries=pd.DataFrame({})\n",
    "TVseries['Name'] = Name\n",
    "TVseries['Year Span'] = Year_span\n",
    "TVseries['Genre'] = Genre\n",
    "TVseries['Run Time'] = Run_time\n",
    "TVseries['Ratings'] = Ratings\n",
    "TVseries['Votes'] = Votes\n",
    "TVseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "421298d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7cc56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d0994fb",
   "metadata": {},
   "source": [
    "## 8. Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b5909de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "# get webpage\n",
    "driver.get(\" https://archive.ics.uci.edu/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "481e8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding view all dataset button from the webpage\n",
    "viewall_dataset = driver.find_element(By.XPATH,\"//tbody[1]//tr/td[2]/span[2]/a\")    \n",
    "page_url = viewall_dataset.get_attribute(\"href\")\n",
    "driver.get(page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2999d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching page urls of all datasets \n",
    "view_list = driver.find_element(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[1]/tbody/tr/td[2]/p/a\")  \n",
    "list_url = view_list.get_attribute(\"href\")           \n",
    "driver.get(list_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b1abccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching urls for each dataset\n",
    "dataset_url = driver.find_elements(By.XPATH,\"//p[@class='normal']//b/a\")    \n",
    "\n",
    "urls = []     \n",
    "for i in dataset_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c5eaaa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attributes = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7908bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Scraping Dataset name\n",
    "    try: \n",
    "        dataset_name = driver.find_element(By.XPATH,\"//span[@class='heading']\")\n",
    "        Dataset_name.append(dataset_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping data type\n",
    "    try:\n",
    "        data_type = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr/td[2]\")\n",
    "        if data_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(data_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    \n",
    "    \n",
    "    #scraping Task\n",
    "    try:\n",
    "        task = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[3]/td[2]\")\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping Attribute type\n",
    "    try:\n",
    "        attribute_type = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[2]\")\n",
    "        if attribute_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Attribute_type.append(attribute_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping No of instances\n",
    "    try:\n",
    "        instances = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr/td[4]\")\n",
    "        if instances.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_instances.append(instances.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping No of attributes\n",
    "    try:\n",
    "        attribute = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[4]\")\n",
    "        if attribute.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_attributes.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attributes.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping year\n",
    "    try:\n",
    "        year = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[6]\")\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0abf0043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instance</th>\n",
       "      <th>No of attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4 GHZ Indoor Channel Measurements Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>7840</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Road Network (North Jutland, Denmark) Data Set</td>\n",
       "      <td>Sequential, Text</td>\n",
       "      <td>Regression, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>434874</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3W dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>1984</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9mers from cullpdb Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>158716</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Simulated Data set of Iraqi tourism places D...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>232</td>\n",
       "      <td>16</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Youtube cookery channels viewers comments in H...</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>YouTube Multiview Video Games Dataset Data Set</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>120000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>YouTube Spam Collection Data Set</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1956</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Z-Alizadeh Sani Data Set</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>56</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Zoo Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>101</td>\n",
       "      <td>17</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Data Name  \\\n",
       "0         2.4 GHZ Indoor Channel Measurements Data Set   \n",
       "1    3D Road Network (North Jutland, Denmark) Data Set   \n",
       "2                                  3W dataset Data Set   \n",
       "3                          9mers from cullpdb Data Set   \n",
       "4    : Simulated Data set of Iraqi tourism places D...   \n",
       "..                                                 ...   \n",
       "617  Youtube cookery channels viewers comments in H...   \n",
       "618     YouTube Multiview Video Games Dataset Data Set   \n",
       "619                   YouTube Spam Collection Data Set   \n",
       "620                           Z-Alizadeh Sani Data Set   \n",
       "621                                       Zoo Data Set   \n",
       "\n",
       "                     Data Type                        Task  \\\n",
       "0                 Multivariate              Classification   \n",
       "1             Sequential, Text      Regression, Clustering   \n",
       "2    Multivariate, Time-Series  Classification, Clustering   \n",
       "3                   Sequential  Classification, Regression   \n",
       "4                 Multivariate  Classification, Clustering   \n",
       "..                         ...                         ...   \n",
       "617         Multivariate, Text              Classification   \n",
       "618         Multivariate, Text  Classification, Clustering   \n",
       "619                       Text              Classification   \n",
       "620                          -              Classification   \n",
       "621               Multivariate              Classification   \n",
       "\n",
       "           Attribute type No of instance No of attributes  Year  \n",
       "0                    Real           7840                5  2018  \n",
       "1                    Real         434874                4  2013  \n",
       "2           Integer, Real           1984                8  2019  \n",
       "3                    Real         158716                4  2021  \n",
       "4                       -            232               16  2020  \n",
       "..                    ...            ...              ...   ...  \n",
       "617                     -           9800                3  2019  \n",
       "618         Integer, Real         120000          1000000  2013  \n",
       "619                     -           1956                5  2017  \n",
       "620         Integer, Real            303               56  2017  \n",
       "621  Categorical, Integer            101               17  1990  \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe \n",
    "\n",
    "ML=pd.DataFrame({})\n",
    "ML['Data Name'] = Dataset_name[:622]\n",
    "ML['Data Type'] = Data_type[:622]\n",
    "ML['Task'] = Task[:622]\n",
    "ML['Attribute type'] = Attribute_type[:622]\n",
    "ML['No of instance'] = No_of_instances[:622]\n",
    "ML['No of attributes'] = No_of_attributes[:622]\n",
    "ML['Year'] = Year[:622]\n",
    "ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89821447",
   "metadata": {},
   "source": [
    "## 9. Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfacf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "driver.maximize_window()\n",
    "# Getting the webpage of mentioned url \n",
    "url=('https://www.naukri.com/hr-recruiters-consultants')\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "212160c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_rec = driver.find_element(By.XPATH,'//input[@class=\"sugInp\"]')\n",
    "search_rec.send_keys(\"Data Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "941240ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element(By.XPATH,'//button[@class=\"fl qsbSrch blueBtn\"]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb3a7b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Name = []\n",
    "Designation = []\n",
    "Company = []\n",
    "Skills = []\n",
    "Location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13470517",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "#Scraping data of Names\n",
    "    for i in driver.find_elements(By.XPATH,\"//span[@class='fl ellipsis']\"):\n",
    "        Name.append(i.text)\n",
    "    time.sleep(3)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"-\")\n",
    "#Scraping data of Designation\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//span[@class='ellipsis clr']\"):\n",
    "        Designation.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Designation.append(\"-\")\n",
    "#Scraping data of company name\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='vcard']//p[1]/a[2]\"):\n",
    "        Company.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Company.append(\"-\")\n",
    "\n",
    "#Scraping data of locations\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//small[@class=\"ellipsis\"]'):\n",
    "        Location.append(i.text)\n",
    "    time.sleep(3)\n",
    "except NoSuchElementException:\n",
    "    Location.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb08455c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Codeachive learning</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>BIZ INFOTECNO PRIVATE LIMITED</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Deeparchi Sharma</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>ZIGRAM</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>NETAPS FOUNDATION</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Avnish Mishra</td>\n",
       "      <td>Senior Technical &amp;amp; Corporate Recruiter</td>\n",
       "      <td>RMS Risk Management Solutions</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Avodha</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Nikitha Palaparthi</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>Aligarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Salt Lake City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>MYSORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5    Abhishek - Only Analytics Hiring - India and   \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                                Kalpana Dumpala   \n",
       "11                                        Mubarak   \n",
       "12                                 Kushal Rastogi   \n",
       "13                                 Priyanka Akiri   \n",
       "14                                   Kapil Devang   \n",
       "15                             Mahesh Babu Channa   \n",
       "16                             Vaishnavi Kudalkar   \n",
       "17                                Sakshi Chhikara   \n",
       "18                                    Ruchi Dhote   \n",
       "19                                  Manisha Yadav   \n",
       "20                                    Riya Rajesh   \n",
       "21                           Rashmi Bhattacharjee   \n",
       "22                                  Faizan Kareem   \n",
       "23                                 Rithika dadwal   \n",
       "24                             Sandhya Khandagale   \n",
       "25                                      Shaun Rao   \n",
       "26                               Deeparchi Sharma   \n",
       "27                                  Azahar Shaikh   \n",
       "28                                          Manas   \n",
       "29                                          kumar   \n",
       "30                                   Sunil Vedula   \n",
       "31                                    Rajat Kumar   \n",
       "32                                Dhruv Dev Dubey   \n",
       "33                                  Avnish Mishra   \n",
       "34                                      Jayanth N   \n",
       "35                                         Avodha   \n",
       "36                                    Priya Khare   \n",
       "37                                    Amit Sharma   \n",
       "38                                          Kanan   \n",
       "39                           Shashikant Chaudhary   \n",
       "40                                           Brad   \n",
       "41                                   Rutuja Pawar   \n",
       "42                            Madhusudhan Sridhar   \n",
       "43                                    Ankit Sinha   \n",
       "44                                 Gaurav Chouhan   \n",
       "45                                   Rashi Kacker   \n",
       "46                                        Ashwini   \n",
       "47                                   Balaji Kolli   \n",
       "48                                 Rajani Nagaraj   \n",
       "49                                    ROHIT Kumar   \n",
       "\n",
       "                                   Designation  \\\n",
       "0                                   HR Manager   \n",
       "1                            Company Recruiter   \n",
       "2                                   Company HR   \n",
       "3                            Company Recruiter   \n",
       "4                                  Founder CEO   \n",
       "5                  Recruitment Lead Consultant   \n",
       "6                            Programme Manager   \n",
       "7                             HR Administrator   \n",
       "8                                     Director   \n",
       "9                               Human Resource   \n",
       "10                            Executive Hiring   \n",
       "11                                  Company HR   \n",
       "12                                  Company HR   \n",
       "13                                  HR Manager   \n",
       "14                                  HR Manager   \n",
       "15                                HR Team Lead   \n",
       "16                                HR Executive   \n",
       "17                        Assistant Manager HR   \n",
       "18         Senior Executive Talent Acquisition   \n",
       "19                                HR Executive   \n",
       "20                  Manager Talent Acquisition   \n",
       "21                                     HR Head   \n",
       "22                                  HR MANAGER   \n",
       "23                                HR Recruiter   \n",
       "24                                HR Recruiter   \n",
       "25                     Manager Human Resources   \n",
       "26                           Company Recruiter   \n",
       "27                           Company Recruiter   \n",
       "28                     Lead Talent acquisition   \n",
       "29                                  Proprietor   \n",
       "30                                         CEO   \n",
       "31                                 Founder CEO   \n",
       "32                    Company Recruitment Head   \n",
       "33  Senior Technical &amp; Corporate Recruiter   \n",
       "34                             Project Manager   \n",
       "35              Business Development Associate   \n",
       "36                              Senior Manager   \n",
       "37                                  Consultant   \n",
       "38                senior technology instructor   \n",
       "39                    HR Recruiter/HR Excutive   \n",
       "40               Manager, Technical Recruiting   \n",
       "41                         Technical Recruiter   \n",
       "42                             Erp Implementer   \n",
       "43                              Head Analytics   \n",
       "44                     Chief Technical Officer   \n",
       "45                          Sr Product Manager   \n",
       "46                    Director Global Delivery   \n",
       "47                                  Co Founder   \n",
       "48                                  HR Manager   \n",
       "49                                   Architect   \n",
       "\n",
       "                                           Company                  Location  \n",
       "0                             Data Science Network                     Delhi  \n",
       "1                    Shore Infotech India Pvt. Ltd  Hyderabad / Secunderabad  \n",
       "2                         MARSIAN Technologies LLP                      Pune  \n",
       "3            Enerlytics Software Solutions Pvt Ltd                 Ahmedabad  \n",
       "4                                  LibraryXProject             UK - (london)  \n",
       "5       Apidel Technologies Division of Transpower         Vadodara / Baroda  \n",
       "6                                             IFMR                   Chennai  \n",
       "7                      Techvantage Systems Pvt Ltd                Trivandrum  \n",
       "8                       Weupskill- Live Wire India                    Indore  \n",
       "9                 CBL Data Science Private Limited     Bengaluru / Bangalore  \n",
       "10                              Innominds Software  Hyderabad / Secunderabad  \n",
       "11                                        MoneyTap     Bengaluru / Bangalore  \n",
       "12              QuantMagnum Technologies Pvt. Ltd.                    Mumbai  \n",
       "13                   Infinitive Software Solutions                 Hyderabad  \n",
       "14                                  BISP Solutions                    Bhopal  \n",
       "15                               SocialPrachar.com  Hyderabad / Secunderabad  \n",
       "16                             Codeachive learning                    Mumbai  \n",
       "17                   BIZ INFOTECNO PRIVATE LIMITED                Chandigarh  \n",
       "18                           Bristlecone India Ltd                      Pune  \n",
       "19                                        Easi Tax               Navi Mumbai  \n",
       "20                     Novelworx Digital Solutions                    Cochin  \n",
       "21         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...                     Delhi  \n",
       "22                   FirstTech Consaltants Pvt.Ltd  Hyderabad / Secunderabad  \n",
       "23                                Affine Analytics                      Pune  \n",
       "24                 Compumatrice Multimedia Pvt Ltd                      Pune  \n",
       "25                              Exela Technologies                      Pune  \n",
       "26                                          ZIGRAM                   Gurgaon  \n",
       "27                 NEAL ANALYTICS SERVICES PVT LTD                      Pune  \n",
       "28      Autumn Leaf Consulting Services Private...     Bengaluru / Bangalore  \n",
       "29                                         trainin     Bengaluru / Bangalore  \n",
       "30                            Nanoprecise Sci Corp                     Delhi  \n",
       "31                  R.S Consultancy &amp; Services     Bengaluru / Bangalore  \n",
       "32                               NETAPS FOUNDATION                     Noida  \n",
       "33                   RMS Risk Management Solutions           Mysoru / Mysore  \n",
       "34        Dollarbird Information Services Pvt, Ltd  Hyderabad / Secunderabad  \n",
       "35                              Nikitha Palaparthi     Bengaluru / Bangalore  \n",
       "36                          Independent Consultant                 New Delhi  \n",
       "37                                 ASCO consulting                   Chennai  \n",
       "38                                         NY INST                   Aligarh  \n",
       "39  3D India Staffing Research &amp; Consulting...            Salt Lake City  \n",
       "40                                     O.C. Tanner                      Pune  \n",
       "41                                   Demand Matrix     Bengaluru / Bangalore  \n",
       "42                             MADHUSUDHAN SRIDHAR                    Mumbai  \n",
       "43                                  Suntech Global                    Indore  \n",
       "44                        Strategic Consulting Lab     Bengaluru / Bangalore  \n",
       "45                            Impel Labs Pvt. Ltd.                    MYSORE  \n",
       "46                                    MRP Advisers  Hyderabad / Secunderabad  \n",
       "47                   Saras Solutions India Pvt Ltd     Bengaluru / Bangalore  \n",
       "48                                     WildJasmine                    Mumbai  \n",
       "49                             LNT Private Limited                         -  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Naukri=pd.DataFrame({})\n",
    "Naukri['Name'] = Name\n",
    "Naukri['Designation'] = Designation\n",
    "Naukri['Company'] = Company\n",
    "Naukri['Location'] = Location\n",
    "Naukri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498598a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
